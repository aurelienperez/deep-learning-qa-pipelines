# Evaluating Question Answering Pipelines with and without Large Language Models
📔 This repository contains the final report of a deep learning project conducted as part of the course  
**“Machine Learning, Neural Networks and Deep Learning”**, in the **Master Probabilités et Finance** at  
**Sorbonne Université** and **École Polytechnique**.

🔎 The project explores several approaches to question answering, combining classical information retrieval techniques  
(BM25, MiniLM, Roberta) with deep learning models (GPT-2, LLaMA 3.2, GPT-3.5).  
Pipelines are evaluated on the NQ-Open dataset using an exact match metric.

**📎 Document:** 
[Evaluating_QA_Pipelines.pdf](./Evaluating_QA_Pipelines.pdf)
